{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Learning in Jax (Practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import numpy as np\n",
    "from typing import Tuple, Dict, List\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typings\n",
    "Task = Tuple[Tuple[jnp.ndarray, jnp.ndarray], Tuple[jnp.ndarray, jnp.ndarray]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sin_task(key: random.PRNGKey, k, test_size=10) -> Tuple[random.PRNGKey, Task]:\n",
    "    key, A_key, w_key, b_key = random.split(key, 4)\n",
    "    key, input_key = random.split(key)\n",
    "\n",
    "    # Generate random parameters for the sin curve\n",
    "    A = random.uniform(A_key, minval=0.1, maxval=5)\n",
    "    w = random.uniform(w_key, minval=0.8, maxval=1.2)\n",
    "    b = random.uniform(b_key, minval=0, maxval=jnp.pi)\n",
    "\n",
    "    # Generate random training input values\n",
    "    x_train = random.uniform(input_key, shape=(k,1), minval=-5, maxval=5)\n",
    "\n",
    "    # Generate random testing input values\n",
    "    x_test = random.uniform(input_key, shape=(test_size,1), minval=-5, maxval=5)\n",
    "\n",
    "    # Calculate traning output\n",
    "    y_train = A * jnp.sin(w * x_train + b)\n",
    "\n",
    "    # Calculate testing output\n",
    "    y_test = A * jnp.sin(w * x_test + b)\n",
    "\n",
    "    d_train = (x_train, y_train)\n",
    "    d_test = (x_test, y_test)\n",
    "    task = (d_train, d_test)\n",
    "\n",
    "    return key, task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskLoader:\n",
    "    def __init__(self, dataset: List[Task], batch_size: int):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        length = len(self.dataset)\n",
    "        for i in range(0, length, self.batch_size):\n",
    "            yield self.convert_to_batch(self.dataset[i:i+self.batch_size])\n",
    "    \n",
    "    def convert_to_batch(self, tasks):\n",
    "        x_train = []\n",
    "        x_test = []\n",
    "        y_train = []\n",
    "        y_test = []\n",
    "        for task in tasks:\n",
    "            d_train, d_test = task\n",
    "            x_train.append(d_train[0])\n",
    "            x_test.append(d_test[0])\n",
    "            y_train.append(d_train[1])\n",
    "            y_test.append(d_test[1])\n",
    "        return (jnp.stack(x_train), jnp.stack(y_train)), (jnp.stack(x_test), jnp.stack(y_test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_train_dataset(key: random.PRNGKey, num_tasks: int, shots=5) -> Tuple[random.PRNGKey, List[Task]]:\n",
    "    tasks = []\n",
    "    for _ in range(num_tasks):\n",
    "        key, task = generate_sin_task(key, shots)\n",
    "        tasks.append(task)\n",
    "    return key, tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_test_dataset(key: random.PRNGKey, num_tasks: int = 100, shots=5) -> Tuple[random.PRNGKey, List[Task]]:\n",
    "    tasks = []\n",
    "    for _ in range(num_tasks):\n",
    "        key, task = generate_sin_task(key, shots, test_size=100)\n",
    "        tasks.append(task)\n",
    "    return key, tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation\n",
    "@jax.jit\n",
    "def relu(x):\n",
    "    return jnp.maximum(x, 0)\n",
    "\n",
    "@jax.jit\n",
    "def tanh(x):\n",
    "    return jnp.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "def forward(params, x: jnp.ndarray) -> jnp.ndarray:\n",
    "    for param in params[:-1]:\n",
    "        w = param['w']\n",
    "        b = param['b']\n",
    "        x = w.T @ x + b\n",
    "        x = relu(x)\n",
    "\n",
    "    w = params[-1]['w']\n",
    "    b = params[-1]['b']\n",
    "    x = w.T @ x + b\n",
    "    # x = 5 * tanh(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(prediction: jnp.ndarray, target: jnp.ndarray) -> jnp.ndarray:\n",
    "    return jnp.mean((prediction - target) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    \n",
    "    @jax.jit\n",
    "    def SGD(params, grads, lr):\n",
    "        return jax.tree_multimap(\n",
    "      lambda p, g: p - lr * g, params, grads\n",
    "    )\n",
    "\n",
    "    @jax.jit\n",
    "    def MetaSGD(theta, alpha, grads):\n",
    "      return jax.tree_multimap(\n",
    "        lambda t, a, g: t - a * g, theta, alpha, grads\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(param_key, layers):\n",
    "    theta = []\n",
    "    keys = random.split(param_key, len(layers)-1)\n",
    "    for (l1, l2, key) in zip(layers[:-1], layers[1:], keys):\n",
    "        w = random.normal(key, (l1, l2))*0.01\n",
    "        b = jnp.zeros(shape=(l2,), dtype=jnp.float32)\n",
    "        theta.append({'w': w, 'b': b})\n",
    "    return tuple(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(0)\n",
    "key, param_key = random.split(key)\n",
    "meta_train_key, meta_test_key = random.split(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "shots = 5\n",
    "task_size = 400\n",
    "_, meta_train_dataset = get_meta_train_dataset(meta_train_key, num_tasks=task_size, shots=shots)\n",
    "_, meta_test_dataset = get_meta_test_dataset(meta_test_key, num_tasks=100, shots=shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "dims = [1, 40, 40, 1]\n",
    "theta = init_params(param_key, layers=dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "fas = 1\n",
    "beta = 0.01\n",
    "task_loader = TaskLoader(meta_train_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This deals with input batches on a single task\n",
    "def loss_fn(theta, data):\n",
    "    x, y = data\n",
    "    logits = jax.vmap(forward, in_axes=(None, 0))(theta, x)\n",
    "    return mse(logits, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def adapt(theta, data, lr):\n",
    "    grads = jax.grad(loss_fn)(theta, data)\n",
    "    return Optimizer.SGD(theta, grads, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_loss_fn(theta, tasks, lr):\n",
    "    def single_meta_loss_fn(theta, task, lr):\n",
    "        d_train, d_test = task\n",
    "        theta_prime = adapt(theta, d_train, lr)\n",
    "        return loss_fn(theta_prime, d_test)\n",
    "    return jnp.mean(jax.vmap(single_meta_loss_fn, in_axes=(None, ((0, 0), (0, 0)), None))(theta, tasks, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def meta_optimize(theta, tasks, alpha, beta):\n",
    "    loss, meta_grads = jax.value_and_grad(meta_loss_fn)(theta, tasks, lr=alpha)\n",
    "    theta = Optimizer.SGD(theta, meta_grads, lr=beta)\n",
    "    return theta, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta training\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = []\n",
    "    for tasks in task_loader:\n",
    "        theta, loss = meta_optimize(theta, tasks, alpha, beta)\n",
    "        running_loss.append(loss)\n",
    "    loss = jnp.mean(jnp.array(running_loss))\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {loss}\")\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta testing\n",
    "task_loader = TaskLoader(meta_test_dataset, batch_size=1)\n",
    "total_loss = []\n",
    "\n",
    "for task in task_loader:\n",
    "    meta_loss = meta_loss_fn(theta, task, alpha)\n",
    "    total_loss.append(meta_loss)\n",
    "loss = jnp.mean(jnp.stack(total_loss))\n",
    "\n",
    "print(f\"Meta test loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## META-SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "key = random.PRNGKey(0)\n",
    "key, param_key = random.split(key)\n",
    "meta_train_key, meta_test_key = random.split(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_alpha(alpha_key, layers):\n",
    "    a = random.uniform(alpha_key, (1,), minval=0.005, maxval=0.1).item()\n",
    "    alpha = []\n",
    "    for (l1, l2) in zip(layers[:-1], layers[1:]):\n",
    "        w = jnp.full((l1, l2), a)\n",
    "        b = jnp.full((l2,), a)\n",
    "        alpha.append({'w': w, 'b': b})\n",
    "    return tuple(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "shots = 5\n",
    "task_size = 400\n",
    "_, meta_train_dataset = get_meta_train_dataset(meta_train_key, num_tasks=task_size, shots=shots)\n",
    "_, meta_test_dataset = get_meta_test_dataset(meta_test_key, num_tasks=100, shots=shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "alpha_key, _ = random.split(param_key)\n",
    "dims = [1, 40, 40, 1]\n",
    "theta = init_params(param_key, layers=dims)\n",
    "alpha = init_alpha(alpha_key, layers=dims)\n",
    "params = (theta, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 116\n",
    "fas = 1\n",
    "beta = 0.01\n",
    "task_loader = TaskLoader(meta_train_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This deals with input batches on a single task\n",
    "def loss_fn(theta, data):\n",
    "    x, y = data\n",
    "    logits = jax.vmap(forward, in_axes=(None, 0))(theta, x)\n",
    "    return mse(logits, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def adapt(params, data):\n",
    "    theta, alpha = params\n",
    "    grads = jax.grad(loss_fn)(theta, data)\n",
    "    return Optimizer.MetaSGD(theta, alpha, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_loss_fn(params, tasks):\n",
    "    def single_meta_loss_fn(params, task):\n",
    "        d_train, d_test = task\n",
    "        theta_prime = adapt(params, d_train)\n",
    "        return loss_fn(theta_prime, d_test)\n",
    "    return jnp.mean(jax.vmap(single_meta_loss_fn, in_axes=(None, ((0, 0), (0, 0))))(params, tasks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def meta_optimize(params, tasks, beta):\n",
    "    loss, meta_grads = jax.value_and_grad(meta_loss_fn)(params, tasks)\n",
    "    params = Optimizer.SGD(params, meta_grads, lr=beta)\n",
    "    return params, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 116, Loss: 0.871147871017456\n"
     ]
    }
   ],
   "source": [
    "# Meta training\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = []\n",
    "    for tasks in task_loader:\n",
    "        params, loss = meta_optimize(params, tasks, beta)\n",
    "        running_loss.append(loss)\n",
    "    loss = jnp.mean(jnp.array(running_loss))\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {loss}\")\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'b': DeviceArray([ 0.07510047, -0.03043799,  0.09361773,  0.09383196,\n",
       "               -0.04353495,  0.35591167,  0.16577566,  0.00849801,\n",
       "                0.05657737,  0.33873984,  0.10075056, -0.04562387,\n",
       "               -0.10016309, -0.0271682 ,  0.09440634,  0.30484062,\n",
       "                0.09440784, -0.32592985, -0.02220334,  0.0944064 ,\n",
       "                0.0944078 , -0.01428996,  0.04325764, -0.22249158,\n",
       "                0.04611416,  0.09839371,  0.22376578, -0.00235719,\n",
       "                0.17428641,  0.4524485 ,  0.04886561,  0.09440812,\n",
       "                0.00126575,  0.0431421 ,  0.07989103,  0.09440958,\n",
       "                0.5607324 ,  0.09440977,  0.21418506,  0.2607757 ],            dtype=float32, weak_type=True),\n",
       "  'w': DeviceArray([[ 0.1806522 , -0.07453348,  0.09189415,  0.09439375,\n",
       "                -0.04526986, -0.07164492,  0.18109062, -0.00610501,\n",
       "                 0.04987805, -0.03284879,  0.03893312,  0.075978  ,\n",
       "                 0.1580771 , -0.01073916,  0.09440987,  0.09301425,\n",
       "                 0.09441046, -0.02502383,  0.06905876,  0.09441628,\n",
       "                 0.09441879, -0.08501513,  0.02621926,  0.14049366,\n",
       "                 0.100646  ,  0.12008489, -0.18047361, -0.0962949 ,\n",
       "                 0.111632  , -0.04479278, -0.07654971,  0.09443834,\n",
       "                 0.03892346, -0.06767399,  0.04711041,  0.09441524,\n",
       "                -0.1677235 ,  0.09444556,  0.06396777, -0.03692393]],            dtype=float32, weak_type=True)},\n",
       " {'b': DeviceArray([ 0.07840732,  0.15939996,  0.08618215,  0.01822887,\n",
       "                0.07572123,  0.15078871,  0.27881718,  0.67668897,\n",
       "               -0.11711119,  0.0030877 , -0.19138448,  0.16989338,\n",
       "               -0.02056359, -0.27170458,  0.08221532,  0.09482531,\n",
       "                0.09315883,  0.08221582,  0.365452  ,  0.08556484,\n",
       "                0.08286306, -0.05063026,  0.08467022,  0.03071182,\n",
       "               -0.10468541, -0.05601679,  0.22559051,  0.12968042,\n",
       "                0.07232383,  0.07400417,  0.08215456,  0.17006785,\n",
       "                0.08652291,  0.07685323, -0.08238623,  0.07180473,\n",
       "                0.0885757 ,  0.09862166,  0.00177711,  0.09108847],            dtype=float32, weak_type=True),\n",
       "  'w': DeviceArray([[ 0.09260395,  0.05058978,  0.09327605, ...,  0.10138542,\n",
       "                -0.07456926,  0.09410911],\n",
       "               [ 0.09089948,  0.0623797 ,  0.09353161, ...,  0.08744939,\n",
       "                -0.04080033,  0.09256258],\n",
       "               [ 0.09440868,  0.0944047 ,  0.09440667, ...,  0.0944065 ,\n",
       "                 0.09431271,  0.09440651],\n",
       "               ...,\n",
       "               [ 0.09440621,  0.09440621,  0.09440621, ...,  0.09440621,\n",
       "                 0.09440621,  0.09440621],\n",
       "               [ 0.09453098,  0.06634343,  0.09462862, ...,  0.09454691,\n",
       "                 0.08476982,  0.09414718],\n",
       "               [ 0.09221265,  0.09296264,  0.09371368, ...,  0.09391792,\n",
       "                 0.01571507,  0.09431264]], dtype=float32, weak_type=True)},\n",
       " {'b': DeviceArray([-0.10174379], dtype=float32, weak_type=True),\n",
       "  'w': DeviceArray([[ 0.12164718],\n",
       "               [-0.01546639],\n",
       "               [ 0.11794454],\n",
       "               [ 0.1162765 ],\n",
       "               [ 0.13963024],\n",
       "               [-0.00891089],\n",
       "               [-0.00293127],\n",
       "               [-0.11394592],\n",
       "               [ 0.460757  ],\n",
       "               [-0.06653553],\n",
       "               [-0.04034795],\n",
       "               [-0.25046495],\n",
       "               [-0.05873837],\n",
       "               [ 0.01716455],\n",
       "               [ 0.05879494],\n",
       "               [ 0.09176882],\n",
       "               [ 0.09847572],\n",
       "               [ 0.04764384],\n",
       "               [ 0.37369466],\n",
       "               [ 0.06257828],\n",
       "               [ 0.13750337],\n",
       "               [-0.15726288],\n",
       "               [ 0.09706837],\n",
       "               [ 0.3958905 ],\n",
       "               [-0.02300878],\n",
       "               [ 0.34053507],\n",
       "               [-0.0218901 ],\n",
       "               [ 0.11847763],\n",
       "               [ 0.28215107],\n",
       "               [ 0.37290454],\n",
       "               [ 0.14161891],\n",
       "               [-0.07800174],\n",
       "               [ 0.1399441 ],\n",
       "               [ 0.18642063],\n",
       "               [-0.03560093],\n",
       "               [ 0.3013867 ],\n",
       "               [ 0.09839884],\n",
       "               [ 0.0979578 ],\n",
       "               [ 0.31866014],\n",
       "               [ 0.07855785]], dtype=float32, weak_type=True)})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta test loss: 1.063297152519226\n"
     ]
    }
   ],
   "source": [
    "# Meta testing\n",
    "task_loader = TaskLoader(meta_test_dataset, batch_size=1)\n",
    "total_loss = []\n",
    "\n",
    "for task in task_loader:\n",
    "    meta_loss = meta_loss_fn(params, task)\n",
    "    total_loss.append(meta_loss)\n",
    "loss = jnp.mean(jnp.stack(total_loss))\n",
    "\n",
    "print(f\"Meta test loss: {loss}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ac930d80a0715647d165be62ffc7f04b227071a0cc0b127f2abd9d5c7233e32"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('jax-cpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
